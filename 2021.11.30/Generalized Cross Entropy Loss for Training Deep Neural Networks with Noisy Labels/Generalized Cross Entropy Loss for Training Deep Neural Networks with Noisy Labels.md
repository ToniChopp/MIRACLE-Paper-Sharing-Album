# <center>Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels</center>
#### <p align="right">By Zhen Huang</p>
## 1. Introduction
论文地址：https://papers.nips.cc/paper/8094-generalized-cross-entropy-loss-for-training-deep-neural-networks-with-noisy-labels.pdf。出自NIPS2018。

在人工智能算法的实际应用场景中，不可避免地会出现训练数据误标现象，即训练数据集上存在**标签噪声**。这会降低所训模型的泛化能力。尤其是对于**深度神经网络**这种描述能力极强的模型，标签噪声对推理精度的影响甚或是灾难性的。论文证实了一个简单的两层网络就能记住所有随机分配的标签。

常见的在有噪环境下，提高实验效果的方法有：

1.去除/纠正噪声数据，但它的成本较高。

2.设计更好的网格结构，如resnet和vggnet。

3.设计对噪声不敏感的loss function。

这篇paper采用了第三种方法，介绍了一种对标**签噪声鲁棒的损失函数**，即General Cross Entropy (GCE)。这种损失函数在2018年的NIPS会议论文中被提出，它集成了Mean Absolute Error (MAE)损失函数的噪声鲁棒性，以及传统的Cross Entropy损失函数的训练高效性。


## 2. 知识整理
### 2.1 CCE（Categorical Cross Entropy）

当前最常用的损失函数是交叉熵损失函数，但已经有相关工作证明Cross Entropy容易过拟合，同时已经证明选取mean absolute error (MAE) 可以有效抑制噪声数据，但MAE存在收敛速度慢、训练困难的问题。

![image-20220128192011233](C:\Users\Hz\AppData\Roaming\Typora\typora-user-images\image-20220128192011233.png)

具体分析而言，首先交叉熵不具有**对称性**，我们优化的目标是使得ρ之后的Loss function相加为常数C，这样才能使得有噪和无噪情况下的优化目标相同，而显然Cross Entropy不具有这样的性质。

<img src="C:\Users\Hz\AppData\Roaming\Typora\typora-user-images\image-20220128192205785.png" alt="image-20220128192205785" style="zoom:50%;" />

更具体而言的，从梯度角度出发。

<img src="C:\Users\Hz\AppData\Roaming\Typora\typora-user-images\image-20220128192416808.png" alt="image-20220128192416808" style="zoom:50%;" />

当选用Cross Entropy时，其梯度大小和样本难度有关。具体而言即：

1.预测值和标注值相差越大，回传梯度越大。

2.数据干净时，loss下降很快，模型拟合效果较好。

3.数据有噪声时，模型会死磕错误数据，拟合速度慢并且影响效果。



### 2.2 MAE（Mean Absolute Error）
`MAE`是一种`Symmetric Loss`。

我们考虑一个十分简单的情形：只包含一个训练样本的二分类问题。假设训练样本为 { x , y } \{x, y\} {x,y}，其中 y ∈ { 0 , 1 } y\in\{0, 1\} y∈{0,1}； f θ ( x ) f_\theta(x) fθ(x)为模型输出， θ \theta θ为待优化的参数，损失函数为 l l l。没有标签噪声的情况下，待优化的目标为 l [ f θ ( x ) , y ] l[f_\theta(x),y] l[fθ(x),y]。考虑存在标签噪声的情形，那么样本 x x x有一定概率 ρ \rho ρ被误标为 1 − y 1-y 1−y，那么实际上的优化目标是
$$
(1-\rho)\cdot l[f_\theta(x),y]+\rho \cdot l[f_\theta(x),1-y] 
$$
如果
$$
argmin​l[fθ​(x),y]=θargmin​{(1−ρ)⋅l[fθ​(x),y]+ρ⋅l[fθ​(x),1−y]}
$$
意味着无论有无噪声，该优化问题都会得到同样的解。这时候损失函数就是噪声鲁棒的。
$$
(1−ρ)⋅l[fθ​(x),y]+ρ⋅l[fθ​(x),1−y]=(1−2ρ)⋅l[fθ​(x),y]+ρ⋅{l[fθ​(x),y]+l[fθ​(x),1−y]} 
$$
整理后的第一项是无噪声情况下的优化目标的一个固定倍数。而第二项是当样本标签等概率取遍所有可能值时，所产生的损失值。



### 2.3  GCE

在明了MAE为什么对噪声鲁棒的机理后，我们再来看看Cross Entropy Loss为什么是不鲁棒的。如果还是用一句话来解释，就是因为CE是无界的。考虑(3)式所表达的鲁棒性条件，各个损失项非负，且其和为定值，那么各个损失项必然是有界的。但在CE中，假设 f θ ( x ) f_\theta(x) fθ(x)表示样本 x x x属于类别1的概率，那么损失值是 − log ⁡ f θ ( x ) -\log f_\theta(x) −logfθ(x)或 − log ⁡ ( 1 − f θ ( x ) ) -\log(1-f_\theta(x)) −log(1−fθ(x))。当 f θ ( x ) f_\theta(x) fθ(x)接近于0或者1时，损失值会非常大。这意味着模型会花费更多的功夫在这些样本上。

这一特性是个双刃剑。如果我们所有的训练样本的标注都是正确的，那么这一特性使得模型关注于那些容易被错判的样本，所以训练过程会十分高效。但如果训练样本存在标签噪声，这一特性将使得模型过度关注于误标的样本，以致最终会得到一个过拟合到误标样本的模型。

好，那我们直接使用MAE不就行了么。实际上MAE实战效果并不好。因为MAE是平等地对待各个样本的，所以其收敛速度比较慢 (具体的解释可以参考GCE论文)。

那么一个自然的想法就是能不能在MAE的噪声鲁棒性和CE的快速收敛性之间做一个折中。这就是GCE的基础想法。具体做法是将CE中的 − log ⁡ ( f θ ( x ) ) -\log(f_\theta(x)) −log(fθ(x))项，替换成一个指数项 1 − f θ q ( x ) q \frac{1-f_\theta^q(x)}{q} q1−fθq(x)，其中幂次 q q q为一个超参数，取值范围为 ( 0 , 1 ] (0,1] (0,1]。当 q = 1 q=1 q=1时，该指数项就蜕变为MAE的形式；当 q → 0 q\rightarrow 0 q→0时，由洛必达法则，该指数项将蜕变为CE的形式。所以 q q q控制着在MAE和CE之间的折中程度。原论文中仅给出了 q q q的经验值，并未给出具体的选取方法。

为进一步抑制误标数据的影响，原论文还给出了一种加强版的损失函数，该函数融合了样本选择的思想。其核心想法是，当训练到一定程度后，模型已经获取了关于数据的正确分类的模式信息，此时，如果模型在样本上输出的概率值比较小，那么这些样本很可能是误标样本。因此，若将这些样本从训练数据中剔除，那么接下来的训练可能会更准确。具体做法是：假设在训练过程中validation数据集上准确率最好的模型为 M b e s t \mathcal{M}_{best} Mbest，则在模型训练一定次数后，每隔一定数目的epoch，将 M b e s t \mathcal{M}_{best} Mbest预测的概率值小于 k k k的样本丢弃，而在其余的数据上进行训练。这里又引入了一个新的超参数 k k k。同样的，原论文只给出了一些数据集上的经验值，并未给明确的设置方法。


## 3. 实验结果
以下为在CIFAR-10数据集上，传统的交叉熵损失与广义交叉熵损失的结果对比。所用参数与论文中一致：training/validation/testing数据集大小分别为45000/5000/10000；模型选用ResNet34，注意其中第一个卷积层的参数为kernel_size=3, stride=1，而用于ImageNet数据集时kernel_size=7, stride=2，这是因为CIFAR-10的图片尺寸比较小，另外去除了第一个pooling层； q = 0.7 , k = 0.5 q=0.7, k=0.5 q=0.7,k=0.5；总共训练120个epochs，初始学习速率为1E-2，第40、第80个epoch学习速率递降10倍；从第40个epoch开始，每10个epoch筛选一遍数据。每组实验运行了5次，结果表示为分类准确率的 μ ± σ \mu\pm\sigma μ±σ的形式。复现结果与论文所示大致相当，甚至还要略优于论文中的结果。其中可以看到，存在pair wise类型的标签噪声时，准确率的提升不是特别明显。

<img src="C:\Users\Hz\AppData\Roaming\Typora\typora-user-images\image-20220128203245123.png" alt="image-20220128203245123" style="zoom:50%;" />



## 4. 总结

几乎所有的数据集都因为不可抗力原因含有错误标注数据，而有噪数据和无噪数据以及噪声比例的不同，都会影响到实验结果。所以**带噪学习领域**的研究是十分有意义的。

针对有噪数据，文章提出了一种**结合了MAE和CCE**的新损失函数（GCE），充分利用了MAE的对称性带来的可以有效抑制噪声数据，以及其存在**收敛速度慢、训练困难**的问题和CCE的无对称、快速收敛性质。针对不同的数据集（cifar10，cifar100，fashion-mnist等）设置不同的噪声比例，最终都取得了SOTA结果。作者认为，该损失函数可以很容易地应用于任何现有的DNN架构和算法，同时在各种有噪声的标签场景中产生良好的性能。

同时作者还提出了一种剪枝策略，当预测值p>k时才进行训练，否则认为是噪声直接不参与训练。这样的改进在大多数测试的噪音比例的情况下都取得了更优的结果。

尚未解决的问题：该paper假设标注错误的概率为p，实际情况是因为类别不同可能带来不同的p，此时**对称性就不再成立**。同时，组里讨论的时候也认为**漏标和错标情况**并不完全相同，也需要进一步讨论做对比试验。

本文启发较多，也给了不少trick。在去除/纠正噪声数据、设计改进网络较为费时的情况下，改进loss function也不失为应对有噪数据的好方法。这种方法同样可以迁移到数据均衡、数据增强等领域。





